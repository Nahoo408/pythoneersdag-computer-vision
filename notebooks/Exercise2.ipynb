{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c48703-c4d6-4abe-a4de-4151fd53333e",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Add the project root to sys.path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from utils.image_tools import read_image, show_image, show_img_inline, rgb_to_grayscale, draw_rectangle, draw_rectangle_xyxy, xyxy_to_xywh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea1bdf-1b45-4181-a465-34319e52be45",
   "metadata": {},
   "source": [
    "## 2A: HAAR cascading classifiers (image classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a182e86-b930-46f6-997f-d0375152a740",
   "metadata": {},
   "source": [
    "**Disclaimer**: A thousand apologies for not using eggs in this section. We are painfully aware,\n",
    "so we used cats seeing as they are the next-best thing.\n",
    "\n",
    "Handcrafting features is time consuming and difficult. We just learned that we can automate\n",
    "that, nice! Haar cascading classifiers are an elegant, but relatively simple method for\n",
    "automatically selecting which features are of importance.\n",
    "\n",
    "Let's see how easy it is to use such classifiers using OpenCV.\n",
    "\n",
    "**Note**: it is possible to train cascading classifiers. To do so, you need both positive and negative\n",
    "examples. For every positive example, you need to indicate the location of the object(s) of interest.\n",
    "This data can then be used to train a classifier that is tailor-made for your use-case. We opted not\n",
    "to do this due to the impracticality of OpenCVs cascading classifier training-implementation.\n",
    "If you are interested, check out: **[training cascade classifier](https://docs.opencv.org/4.11.0/dc/d88/tutorial_traincascade.html)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731e9502-e9df-4337-8b48-a02ec8bff5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a relative path to the image\n",
    "image_path = str(project_root / \"data\" / \"exercise2\" / \"cat.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5592f19e-f7d5-4813-9175-90da9c8cd62b",
   "metadata": {},
   "source": [
    "**Exercise 1:** Use the haarcascades classifier on the cat image defined in the previous cell and see how the classifier performs. Thereafter do the following tasks:\n",
    "\n",
    "- Try the classifier on other cat images specified in the cat_collection folder and determine on which images the classifier performs well and where it struggles.\n",
    "\n",
    "- Can you find images that don't contain a cat face but are classified as such.\n",
    "\n",
    "- How does this classifier handle a (partial)covered cat face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b7542-6ded-4a32-abd0-20b2afb346eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_path = f\"{cv2.data.haarcascades}haarcascade_frontalcatface.xml\"\n",
    "\n",
    "cascade_classifier = cv2.CascadeClassifier(classifier_path)\n",
    "# all avaliable classifiers: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "\n",
    "rgb_image = read_image(image_path)\n",
    "gray_image = rgb_to_grayscale(rgb_image)\n",
    "\n",
    "detections = cascade_classifier.detectMultiScale(gray_image)\n",
    "\n",
    "for detection in detections:\n",
    "    draw_rectangle(rgb_image, detection)\n",
    "\n",
    "show_image(rgb_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f859118-7f76-4f65-9075-bd10f927dd1b",
   "metadata": {},
   "source": [
    "## Template matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20624b73-5763-4afc-a624-9e1d27d5cbf5",
   "metadata": {},
   "source": [
    "**Exercise 2:** Another simple method for object detection is template matching. This method requires a template,\n",
    "and the algorithm will try to find the template in the image. Apply the template matching method on the following images and try to exmplain the results:\n",
    "\n",
    "- not_damaged_2.jpg\n",
    "- not_damaged_1.jpg\n",
    "- not_damaged_148.jpg\n",
    "- not_damaged_71.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cecb1db5-021d-4cc3-bc48-9560dc19c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = str(project_root / \"data\" / \"exercise2\" / \"not_damaged_2.jpg\")\n",
    "template_path = str(project_root / \"data\" / \"exercise2\" / \"egg_template.jpg\")\n",
    "threshold = 0.3\n",
    "\n",
    "rgb_image = read_image(image_path)\n",
    "image = rgb_to_grayscale(rgb_image)\n",
    "template = rgb_to_grayscale(read_image(template_path))\n",
    "\n",
    "result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) \n",
    "centers = np.where(result >= threshold) \n",
    "\n",
    "w, h = template.shape[::-1] \n",
    "for x_center, y_center in zip(*centers[::-1]):\n",
    "    draw_rectangle(rgb_image, (x_center, y_center, w, h))\n",
    "\n",
    "show_image(rgb_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
